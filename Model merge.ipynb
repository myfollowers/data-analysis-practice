{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务概述\n",
    "本阶段主要是针对已训练的模型进行融合，得到一个表现更好的模型。融合方法主要有以下几种\n",
    "* 线性加权\n",
    "* 交叉融合\n",
    "* stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler,LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier as kNN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import colorama\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据\n",
    "X_train = pd.read_csv('cle_train.csv')\n",
    "Y_train = pd.read_csv('Y_train.csv', names=['tradeMoney'])\n",
    "X_test = pd.read_csv('clt_test.csv')        #读写清洗之后的测试数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 树模型-lightbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=2333)\n",
    "   \n",
    "    \"===================================第一轮========================================================\"\n",
    "    y_pre_list = []\n",
    "    r2_list = []\n",
    "    train_feat = pd.Series()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(params, trn_data, num_round,valid_sets=[trn_data, val_data], verbose_eval=500,\n",
    "                    early_stopping_rounds=200)\n",
    "        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        r2 = r2_score(y_pre,label[val_idx])\n",
    "        r2_list.append(r2)\n",
    "        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))\n",
    "        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)\n",
    "        y_pre_list.append(y_pre_test)\n",
    "    print('r2 score{:}'.format(r2))\n",
    "    print('r2:{:}'.format(np.mean(r2_list)))\n",
    "\n",
    "    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5\n",
    "    feature['pre'] = train_feat\n",
    "    test['pre'] = y_pred_final\n",
    "    \"===================================第二轮========================================================\"\n",
    "    y_pre_list = []\n",
    "    r2_list = []\n",
    "    train_feat = pd.Series()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(params, trn_data, num_round, feval=get_r2_metric,valid_sets=[trn_data, val_data], verbose_eval=500,\n",
    "                    early_stopping_rounds=200)\n",
    "        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        r2 = r2_score(y_pre,label[val_idx])\n",
    "        r2_list.append(r2)\n",
    "        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))\n",
    "        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)\n",
    "        y_pre_list.append(y_pre_test)\n",
    "    print('r2 score{:}'.format(r2))\n",
    "    print('r2:{:}'.format(np.mean(r2_list)))\n",
    "    \n",
    "    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5\n",
    "    feature['pre_2'] = train_feat\n",
    "    test['pre_2'] = y_pred_final\n",
    "    \"=======================第三轮========================================================\"\n",
    "    y_pre_list = []\n",
    "    r2_list = []\n",
    "    train_feat = pd.Series()\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(feature.values, label)):\n",
    "        print(\"fold {}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(feature.iloc[trn_idx], label[trn_idx], categorical_feature=categorical_feats)\n",
    "        val_data = lgb.Dataset(feature.iloc[val_idx], label[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(params, trn_data, num_round, feval=get_r2_metric,valid_sets=[trn_data, val_data], verbose_eval=500,\n",
    "                    early_stopping_rounds=200)\n",
    "        y_pre = clf.predict(feature.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        r2 = r2_score(y_pre,label[val_idx])\n",
    "        r2_list.append(r2)\n",
    "        train_feat = train_feat.append(pd.Series(y_pre,index=val_idx))\n",
    "        y_pre_test = clf.predict(test,num_iteration=clf.best_iteration)\n",
    "        y_pre_list.append(y_pre_test)\n",
    "    print('r2 score{:}'.format(r2))\n",
    "    print('r2:{:}'.format(np.mean(r2_list)))\n",
    "    \n",
    "    y_pred_final=  (y_pre_list[0]+y_pre_list[1]+y_pre_list[2]+y_pre_list[3]+y_pre_list[4])/5\n",
    "    \n",
    "    return y_pred_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性加权\n",
    "从算法的角度来看，则最常用的是采用加权型的混合推荐技术，即将来自不同推荐算法生成的候选结果及结果的分数，进一步进行组合（Ensemble）加权，生成最终的推荐排序结果。\n",
    "\n",
    "具体来看，比较原始的加权型的方法是根据推荐效果，固定赋予各个子算法输出结果的权重，然后得到最终结果。很显然这种方法无法灵活处理不同的上下文场景，因为不同的算法的结果，可能在不同的场景下质量有高有低，固定加权系统无法各取所长。所以更好的思路是设置训练样本，然后比较用户对推荐结果的评价、与系统的预测是否相符，根据训练得到的结果生成加权的模型，动态的调整权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里选用同一算法，因此权重一样\n",
    "pre = (pre1 + pre2 + pre3 +...+pren )/n\n",
    "pd.DataFrame(pre).to_csv(\"pre.csv\",header=None,index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉融合\n",
    "交叉融合常被称为Blending方法，其思路是在推荐结果中，穿插不同推荐模型的结果，以确保结果的多样性。\n",
    "\n",
    "这种方式将不同算法的结果组合在一起推荐给用户\n",
    "\n",
    "交叉融合法的思路是“各花入各眼”，不同算法的结果着眼点不同，能满足不同用户的需求，直接穿插在一起进行展示。这种融合方式适用于同时能够展示较多条结果的推荐场景，并且往往用于算法间区别较大，如分别基于用户长期兴趣和短期兴趣计算获得的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(train,test,target):\n",
    "    '''5折'''\n",
    "    # n_flods = 5\n",
    "    # skf = list(StratifiedKFold(y, n_folds=n_flods))\n",
    "    '''切分训练数据集为d1,d2两部分'''\n",
    "    X_d1, X_d2, y_d1, y_d2 = train_test_split(train, target, test_size=0.5, random_state=914)\n",
    "\n",
    "    train_ = np.zeros((X_d2.shape[0],len(clfs*3)))\n",
    "    test_ = np.zeros((test.shape[0],len(clfs*3)))\n",
    "\n",
    "    for j,clf in enumerate(clfs):\n",
    "        '''依次训练各个单模型'''\n",
    "        # print(j, clf)\n",
    "        '''使用第1个部分作为预测，第2部分来训练模型，获得其预测的输出作为第2部分的新特征。'''\n",
    "        # X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "        X_d1fillna=X_d1.fillna(0)\n",
    "        X_d2fillna = X_d2.fillna(0)\n",
    "\n",
    "        X_predictfillna= test.fillna(0)\n",
    "\n",
    "        clf.fit(X_d1fillna,y_d1)\n",
    "        y_submission = clf.predict(X_d2fillna)\n",
    "        y_test_submission = clf.predict(X_predictfillna)\n",
    "\n",
    "        train_[:,j*3] = y_submission*y_submission\n",
    "        '''对于测试集，直接用这k个模型的预测值作为新的特征。'''\n",
    "        test_[:, j*3] = y_test_submission*y_test_submission\n",
    "\n",
    "        train_[:, j+1] =(y_submission - y_submission.min()) /(y_submission.max() - y_submission.min())\n",
    "        '''对于测试集，直接用这k个模型的预测值作为新的特征。'''\n",
    "        y_test_submission = (y_test_submission - y_test_submission.min()) / \\\n",
    "                            (y_test_submission.max() - y_test_submission.min())\n",
    "        test_[:, j+1] = y_test_submission\n",
    "\n",
    "        train_[:, j+2] = np.log(y_submission)\n",
    "        '''对于测试集，直接用这k个模型的预测值作为新的特征。'''\n",
    "        y_test_submission =np.log(y_test_submission)\n",
    "        test_[:, j+2] = y_test_submission\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"val auc Score: %f\" % r2_score(y_predict, dataset_d2[:, j]))\n",
    "        print('已完成第',j)\n",
    "\n",
    "    train_.to_csv('./input/train_blending.csv', index=False)\n",
    "    test_.to_csv('./input/test_blending.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "Stacking实际上就是把Blending组合起来，Blending只有一层，而Stacking有多层，它把各个基学习器的预测结果作为下一层新的训练集，来学习一个新的学习器。\n",
    "通过元分类器或元回归聚合多个分类或回归模型。基础层次模型（level model）基于完整的训练集进行训练，然后元模型基于基础层次模型的输出进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以python自带的鸢尾花数据集为例\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "label = ['KNN', 'Random Forest', 'Naive Bayes', 'Stacking Classifier']\n",
    "clf_list = [clf1, clf2, clf3, sclf]\n",
    "    \n",
    "fig = plt.figure(figsize=(10,8))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "grid = itertools.product([0,1],repeat=2)\n",
    "\n",
    "clf_cv_mean = []\n",
    "clf_cv_std = []\n",
    "for clf, label, grd in zip(clf_list, label, grid):\n",
    "        \n",
    "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
    "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
    "    clf_cv_mean.append(scores.mean())\n",
    "    clf_cv_std.append(scores.std())\n",
    "        \n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf)\n",
    "    plt.title(label)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
