{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务概述\n",
    "当对数据和特征做了一些常规处理后，可以采取一些模型对最初的目标进行模型拟合；但模型种类较多，且参数众多，需要选择合适的模型也是一件比较费时的事情。这也是本阶段的主要任务。\n",
    "* 模型筛选\n",
    "* 特征重构\n",
    "* 模型选定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载包\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  #忽略警告\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41440 entries, 0 to 41439\n",
      "Data columns (total 51 columns):\n",
      "ID                    41440 non-null int64\n",
      "area                  41440 non-null float64\n",
      "rentType              41440 non-null object\n",
      "houseType             41440 non-null object\n",
      "houseFloor            41440 non-null object\n",
      "totalFloor            41440 non-null int64\n",
      "houseToward           41440 non-null object\n",
      "houseDecoration       41440 non-null object\n",
      "communityName         41440 non-null object\n",
      "city                  41440 non-null object\n",
      "region                41440 non-null object\n",
      "plate                 41440 non-null object\n",
      "buildYear             41440 non-null object\n",
      "saleSecHouseNum       41440 non-null int64\n",
      "subwayStationNum      41440 non-null int64\n",
      "busStationNum         41440 non-null int64\n",
      "interSchoolNum        41440 non-null int64\n",
      "schoolNum             41440 non-null int64\n",
      "privateSchoolNum      41440 non-null int64\n",
      "hospitalNum           41440 non-null int64\n",
      "drugStoreNum          41440 non-null int64\n",
      "gymNum                41440 non-null int64\n",
      "bankNum               41440 non-null int64\n",
      "shopNum               41440 non-null int64\n",
      "parkNum               41440 non-null int64\n",
      "mallNum               41440 non-null int64\n",
      "superMarketNum        41440 non-null int64\n",
      "totalTradeMoney       41440 non-null int64\n",
      "totalTradeArea        41440 non-null float64\n",
      "tradeMeanPrice        41440 non-null float64\n",
      "tradeSecNum           41440 non-null int64\n",
      "totalNewTradeMoney    41440 non-null int64\n",
      "totalNewTradeArea     41440 non-null int64\n",
      "tradeNewMeanPrice     41440 non-null float64\n",
      "tradeNewNum           41440 non-null int64\n",
      "remainNewNum          41440 non-null int64\n",
      "supplyNewNum          41440 non-null int64\n",
      "supplyLandNum         41440 non-null int64\n",
      "supplyLandArea        41440 non-null float64\n",
      "tradeLandNum          41440 non-null int64\n",
      "tradeLandArea         41440 non-null float64\n",
      "landTotalPrice        41440 non-null int64\n",
      "landMeanPrice         41440 non-null float64\n",
      "totalWorkers          41440 non-null int64\n",
      "newWorkers            41440 non-null int64\n",
      "residentPopulation    41440 non-null int64\n",
      "pv                    41422 non-null float64\n",
      "uv                    41422 non-null float64\n",
      "lookNum               41440 non-null int64\n",
      "tradeTime             41440 non-null object\n",
      "tradeMoney            41440 non-null float64\n",
      "dtypes: float64(10), int64(30), object(11)\n",
      "memory usage: 16.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2469 entries, 0 to 2468\n",
      "Data columns (total 50 columns):\n",
      "ID                    2469 non-null int64\n",
      "area                  2469 non-null float64\n",
      "rentType              2469 non-null object\n",
      "houseType             2469 non-null object\n",
      "houseFloor            2469 non-null object\n",
      "totalFloor            2469 non-null int64\n",
      "houseToward           2469 non-null object\n",
      "houseDecoration       2469 non-null object\n",
      "communityName         2469 non-null object\n",
      "city                  2469 non-null object\n",
      "region                2469 non-null object\n",
      "plate                 2469 non-null object\n",
      "buildYear             2469 non-null object\n",
      "saleSecHouseNum       2469 non-null int64\n",
      "subwayStationNum      2469 non-null int64\n",
      "busStationNum         2469 non-null int64\n",
      "interSchoolNum        2469 non-null int64\n",
      "schoolNum             2469 non-null int64\n",
      "privateSchoolNum      2469 non-null int64\n",
      "hospitalNum           2469 non-null int64\n",
      "drugStoreNum          2469 non-null int64\n",
      "gymNum                2469 non-null int64\n",
      "bankNum               2469 non-null int64\n",
      "shopNum               2469 non-null int64\n",
      "parkNum               2469 non-null int64\n",
      "mallNum               2469 non-null int64\n",
      "superMarketNum        2469 non-null int64\n",
      "totalTradeMoney       2469 non-null int64\n",
      "totalTradeArea        2469 non-null float64\n",
      "tradeMeanPrice        2469 non-null float64\n",
      "tradeSecNum           2469 non-null int64\n",
      "totalNewTradeMoney    2469 non-null int64\n",
      "totalNewTradeArea     2469 non-null int64\n",
      "tradeNewMeanPrice     2469 non-null float64\n",
      "tradeNewNum           2469 non-null int64\n",
      "remainNewNum          2469 non-null int64\n",
      "supplyNewNum          2469 non-null int64\n",
      "supplyLandNum         2469 non-null int64\n",
      "supplyLandArea        2469 non-null float64\n",
      "tradeLandNum          2469 non-null int64\n",
      "tradeLandArea         2469 non-null float64\n",
      "landTotalPrice        2469 non-null int64\n",
      "landMeanPrice         2469 non-null float64\n",
      "totalWorkers          2469 non-null int64\n",
      "newWorkers            2469 non-null int64\n",
      "residentPopulation    2469 non-null int64\n",
      "pv                    2467 non-null float64\n",
      "uv                    2467 non-null float64\n",
      "lookNum               2469 non-null int64\n",
      "tradeTime             2469 non-null object\n",
      "dtypes: float64(9), int64(30), object(11)\n",
      "memory usage: 964.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "data_train = pd.read_csv('train_data.csv')\n",
    "data_test = pd.read_csv('test_a.csv')\n",
    "# 数据预览\n",
    "data_train.info(),data_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清洗训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  108,   146,   228,   230,   255,   277,   310,   319,   348,\n",
      "              369,\n",
      "            ...\n",
      "            38753, 38761, 39141, 39164, 39193, 39256, 39307, 39432, 41210,\n",
      "            41241],\n",
      "           dtype='int64', length=364)\n"
     ]
    }
   ],
   "source": [
    "# 清洗目标数据中的异常值：利用数据本身规律清洗\n",
    "def IF_drop(train):\n",
    "    IForest = IsolationForest(contamination=0.01)\n",
    "    IForest.fit(train[\"tradeMoney\"].values.reshape(-1,1))\n",
    "    y_pred = IForest.predict(train[\"tradeMoney\"].values.reshape(-1,1))\n",
    "    drop_index = train.loc[y_pred==-1].index\n",
    "    print(drop_index)\n",
    "    train.drop(drop_index,inplace=True)\n",
    "    return train\n",
    "\n",
    "data_train = IF_drop(data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1)清洗不符合业务逻辑的数据\n",
    "def dropData(train):\n",
    "    # 丢弃部分异常值\n",
    "    train = train[train.area <= 200]\n",
    "    train = train[(train.tradeMoney <=16000) & (train.tradeMoney >=700)]\n",
    "    train.drop(train[(train['totalFloor'] == 0)].index, inplace=True)\n",
    "    return train  \n",
    "\n",
    "data_train = dropData(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2)清洗不符合业务逻辑的数据\n",
    "def cleanData(data):\n",
    "    data.drop(data[(data['region']=='RG00001') & (data['tradeMoney']<1000)&(data['area']>50)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00001') & (data['tradeMoney']>25000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00001') & (data['area']>250)&(data['tradeMoney']<20000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00001') & (data['area']>400)&(data['tradeMoney']>50000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00001') & (data['area']>100)&(data['tradeMoney']<2000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00002') & (data['area']<100)&(data['tradeMoney']>60000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['area']<300)&(data['tradeMoney']>30000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['tradeMoney']<500)&(data['area']<50)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['tradeMoney']<1500)&(data['area']>100)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['tradeMoney']<2000)&(data['area']>300)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['tradeMoney']>5000)&(data['area']<20)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00003') & (data['area']>600)&(data['tradeMoney']>40000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00004') & (data['tradeMoney']<1000)&(data['area']>80)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00006') & (data['tradeMoney']<200)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00005') & (data['tradeMoney']<2000)&(data['area']>180)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00005') & (data['tradeMoney']>50000)&(data['area']<200)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00006') & (data['area']>200)&(data['tradeMoney']<2000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00007') & (data['area']>100)&(data['tradeMoney']<2500)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00010') & (data['area']>200)&(data['tradeMoney']>25000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00010') & (data['area']>400)&(data['tradeMoney']<15000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00010') & (data['tradeMoney']<3000)&(data['area']>200)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00010') & (data['tradeMoney']>7000)&(data['area']<75)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00010') & (data['tradeMoney']>12500)&(data['area']<100)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00004') & (data['area']>400)&(data['tradeMoney']>20000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00008') & (data['tradeMoney']<2000)&(data['area']>80)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00009') & (data['tradeMoney']>40000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00009') & (data['area']>300)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00009') & (data['area']>100)&(data['tradeMoney']<2000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00011') & (data['tradeMoney']<10000)&(data['area']>390)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00012') & (data['area']>120)&(data['tradeMoney']<5000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00013') & (data['area']<100)&(data['tradeMoney']>40000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00013') & (data['area']>400)&(data['tradeMoney']>50000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00013') & (data['area']>80)&(data['tradeMoney']<2000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['area']>300)&(data['tradeMoney']>40000)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['tradeMoney']<1300)&(data['area']>80)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['tradeMoney']<8000)&(data['area']>200)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['tradeMoney']<1000)&(data['area']>20)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['tradeMoney']>25000)&(data['area']>200)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00014') & (data['tradeMoney']<20000)&(data['area']>250)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00005') & (data['tradeMoney']>30000)&(data['area']<100)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00005') & (data['tradeMoney']<50000)&(data['area']>600)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00005') & (data['tradeMoney']>50000)&(data['area']>350)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00006') & (data['tradeMoney']>4000)&(data['area']<100)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00006') & (data['tradeMoney']<600)&(data['area']>100)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00006') & (data['area']>165)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00012') & (data['tradeMoney']<800)&(data['area']<30)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00007') & (data['tradeMoney']<1100)&(data['area']>50)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00004') & (data['tradeMoney']>8000)&(data['area']<80)].index,inplace=True)\n",
    "    data.loc[(data['region']=='RG00002')&(data['area']>50)&(data['rentType']=='合租'),'rentType']='整租'\n",
    "    data.loc[(data['region']=='RG00014')&(data['rentType']=='合租')&(data['area']>60),'rentType']='整租'\n",
    "    data.drop(data[(data['region']=='RG00008')&(data['tradeMoney']>15000)&(data['area']<110)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00008')&(data['tradeMoney']>20000)&(data['area']>110)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00008')&(data['tradeMoney']<1500)&(data['area']<50)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00008')&(data['rentType']=='合租')&(data['area']>50)].index,inplace=True)\n",
    "    data.drop(data[(data['region']=='RG00015') ].index,inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "data_train = cleanData(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tradeMoney'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tradeMoney'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f3c55339dd7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 目标数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_target\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tradeMoney'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_target\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./评分文件/sub_a_913.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mpop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[1;36m3\u001b[0m  \u001b[0mmonkey\u001b[0m        \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m         \"\"\"\n\u001b[1;32m--> 809\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    810\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tradeMoney'"
     ]
    }
   ],
   "source": [
    "# 目标数据\n",
    "target_train  = data_train.pop('tradeMoney')\n",
    "target_test  = pd.read_csv('./评分文件/sub_a_913.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理缺失和填补\n",
    "def missing(data):\n",
    "    # 删除无用特征\n",
    "    data.drop(['city','ID'], axis = 1, inplace = True)\n",
    "    # 填补缺失或不正常值\n",
    "    buildYear_mode= data['buildYear'][data['buildYear'] != '暂无信息'].mode()\n",
    "    data.loc[data['buildYear'] == '暂无信息','buildYear'] = buildYear_mode[0]\n",
    "    data['buildYear'] = data['buildYear'].astype(int)\n",
    "    data['pv'].fillna(data['pv'].mean(), inplace = True)\n",
    "    data['uv'].fillna(data['uv'].mean(), inplace = True)\n",
    "    return(data)\n",
    "train,test = missing(data_train),missing(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征拆分和融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类变量\n",
    "# 将houseType转为'Room'，'Hall'，'Bath'\n",
    "def housetype(data_train):\n",
    "    def Room(x):\n",
    "        Room = int(x.split('室')[0])\n",
    "        return Room\n",
    "    def Hall(x):\n",
    "        Hall = int(x.split('室')[1].split('厅')[0])\n",
    "        return(Hall)\n",
    "    def Bash(x):\n",
    "        Bash = int(x.split('室')[1].split('厅')[1].split('卫')[0])\n",
    "    data_train['room'] = data_train['houseType'].apply(lambda x :Room(x))\n",
    "    data_train['hall'] = data_train['houseType'].apply(lambda x :Room(x))\n",
    "    data_train['bath'] = data_train['houseType'].apply(lambda x :Room(x))\n",
    "    data_train['bath_room'] = (data_train['bath'] + 1) / (data_train['room'] + 1)\n",
    "    return(data_train)\n",
    "\n",
    "data_train, data_test = housetype(data_train), housetype(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充租房类型\n",
    "def renttype(data_train):\n",
    "    data_train.loc[(data_train['rentType'] == '未知方式') & (data_train['room'] <= 1), 'rentType'] = '整租'\n",
    "    # print(data.loc[(data['rentType']=='未知方式')&(data['Room_Bath']>1),'rentType'])\n",
    "    data_train.loc[(data_train['rentType'] == '未知方式') & (data_train['bath_room'] > 1), 'rentType'] = '合租'\n",
    "    data_train.loc[(data_train['rentType'] == '未知方式') & (data_train['room'] > 1) & (data_train['area'] < 50), 'rentType'] = '合租'\n",
    "    data_train.loc[(data_train['rentType'] == '未知方式') & (data_train['area'] / data_train['room'] < 20), 'rentType'] = '合租'\n",
    "    # data.loc[(data['rentType']=='未知方式')&(data['area']>60),'rentType']='合租'\n",
    "    data_train.loc[(data_train['rentType'] == '未知方式') & (data_train['area'] <= 50) & (data_train['room'] == 2), 'rentType'] = '合租'\n",
    "    data_train.loc[(data_train['rentType'] == '未知方式') & (data_train['area'] > 60) & (data_train['room'] == 2), 'rentType'] = '整租'\n",
    "    data_train.loc[(data_train['rentType'] == '未知方式') & (data_train['area'] <= 60) & (data_train['room'] == 3), 'rentType'] = '合租'\n",
    "    data_train.loc[(data_train['rentType'] == '未知方式') & (data_train['area'] > 60) & (data_train['room'] == 3), 'rentType'] = '整租'\n",
    "    data_train.loc[(data_train['rentType'] == '未知方式') & (data_train['area'] >= 100) & (data_train['room'] > 3), 'rentType'] = '整租'\n",
    "    return(data_train)\n",
    "\n",
    "data_train, data_test = renttype(data_train), renttype(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rentType</th>\n",
       "      <th>area</th>\n",
       "      <th>room</th>\n",
       "      <th>bath</th>\n",
       "      <th>bath_room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>--</td>\n",
       "      <td>63.26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>--</td>\n",
       "      <td>49.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>--</td>\n",
       "      <td>37.80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38122</th>\n",
       "      <td>--</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rentType   area  room  bath  bath_room\n",
       "3978        --  63.26     1     1        1.0\n",
       "4003        --  49.00     2     2        1.0\n",
       "4034        --  37.80     1     1        1.0\n",
       "38122       --  30.00     1     1        1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.loc[data_train['rentType'] == '--',['rentType', 'area', 'room', 'bath', 'bath_room']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对rentType中“--”填补\n",
    "data_train.loc[(data_train['rentType'] == '--') & (data_train['area'] >60) & (data_train['room'] <= 1), 'rentType'] = '整租'\n",
    "data_train.loc[(data_train['rentType'] == '--') & (data_train['area'] >50) & (data_train['room'] == 2), 'rentType'] = '整租'\n",
    "data_train.loc[(data_train['rentType'] == '--')  & (data_train['room'] <= 1), 'rentType'] = '整租'\n",
    "\n",
    "# 是否有必要将‘未知方式’细分全部填补\n",
    "# data_train.loc[data_train['rentType'] == '未知方式',['rentType', 'area', 'room', 'bath', 'bath_room']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理tradeTime\n",
    "def time(data_train):\n",
    "    def month(x):\n",
    "        month = int(x.split('/')[1])\n",
    "        return(month)\n",
    "    def day(x):\n",
    "        day = int(x.split('/')[2])\n",
    "        return(day)\n",
    "    def year(x):\n",
    "        year = int(x.split('/')[2])\n",
    "        return(year)\n",
    "    data_train['month'] = data_train['tradeTime'].apply(lambda x: month(x))\n",
    "    data_train['day'] = data_train['tradeTime'].apply(lambda x: day(x))\n",
    "    data_train['year'] = data_train['tradeTime'].apply(lambda x: year(x))\n",
    "    return(data_train)\n",
    "\n",
    "data_train, data_test = time(data_train), time(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 其余特征融合（脑洞大开）\n",
    "def otherca(data_train):\n",
    "    data_train['pv/uv'] = data_train['pv'] / data_train['uv']\n",
    "    data_train['房间总数'] = data_train['room'] + data_train['hall'] + data_train['bath']\n",
    "\n",
    "    # 公共设施\n",
    "    # 各交通工具权重自定（参照交通工具对租金影响程度而定）\n",
    "    data_train['transportNum'] = 5*data_train['subwayStationNum'] / data_train['subwayStationNum'].mean() + data_train['busStationNum'] / data_train['busStationNum'].mean()\n",
    "    # 教育设施权重（可类比，国际学校，私立学校，公立学校影响）\n",
    "    data_train['all_SchoolNum'] = 2 * data_train['interSchoolNum'] / data_train['interSchoolNum'].mean() + data_train['schoolNum'] / data_train['schoolNum'].mean() + data_train['privateSchoolNum'] / data_train['privateSchoolNum'].mean()\n",
    "    # 商场，同上\n",
    "    data_train['all_mall'] = data_train['mallNum'] / data_train['mallNum'].mean() + data_train['superMarketNum'] / data_train['superMarketNum'].mean()\n",
    "    # 医疗\n",
    "    data_train['all_hospitalNum'] = 2 * data_train['hospitalNum'] / data_train['hospitalNum'].mean() + data_train['drugStoreNum'] / data_train['drugStoreNum'].mean()\n",
    "    # 其他公共设施；体育馆，银行等\n",
    "    data_train['otherNum'] = data_train['gymNum'] / data_train['gymNum'].mean() + data_train['bankNum'] / data_train['bankNum'].mean() + data_train['shopNum'] / data_train['shopNum'].mean() + 2 * data_train['parkNum'] / data_train['parkNum'].mean()\n",
    "\n",
    "    # 删除已用特征\n",
    "    data_train.drop(['houseType','tradeTime','subwayStationNum', 'busStationNum','interSchoolNum', 'schoolNum', 'privateSchoolNum',\n",
    "                   'hospitalNum', 'drugStoreNum', 'mallNum', 'superMarketNum', 'gymNum', 'bankNum', 'shopNum', 'parkNum'],\n",
    "                  axis=1, inplace=True)\n",
    "    return(data_train)\n",
    "\n",
    "data_train, data_test = otherca(data_train), otherca(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算统计特征\n",
    "def featureCount(train,test):\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    def feature_count(data, features=[]):\n",
    "        new_feature = 'count'\n",
    "        for i in features:\n",
    "            new_feature += '_' + i\n",
    "        temp = data.groupby(features).size().reset_index().rename(columns={0: new_feature})\n",
    "        data = data.merge(temp, 'left', on=features)\n",
    "        return data\n",
    "\n",
    "    data = feature_count(data, ['communityName'])\n",
    "    data = feature_count(data, ['buildYear'])\n",
    "    data = feature_count(data, ['totalFloor'])\n",
    "    data = feature_count(data, ['communityName', 'totalFloor'])\n",
    "    data = feature_count(data, ['communityName', 'newWorkers'])\n",
    "    data = feature_count(data, ['communityName', 'totalTradeMoney'])\n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    return new_train, new_test\n",
    "    \n",
    "data_train, data_test = featureCount(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby生成统计特征：mean,std等\n",
    "\n",
    "def groupby(train,test):\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    columns = ['rentType', 'houseFloor', 'houseToward', 'houseDecoration', 'communityName', 'region', 'plate']\n",
    "    for feature in columns:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "\n",
    "    temp = data.groupby('communityName')['area'].agg({'com_area_mean': 'mean', 'com_area_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='communityName', how='left')\n",
    "    \n",
    "    data['price_per_area'] = data.tradeMeanPrice / data.area * 100\n",
    "    temp = data.groupby('communityName')['price_per_area'].agg(\n",
    "        {'comm_price_mean': 'mean', 'comm_price_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='communityName', how='left')\n",
    "   \n",
    "    temp = data.groupby('plate')['price_per_area'].agg(\n",
    "        {'plate_price_mean': 'mean', 'plate_price_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    data.drop('price_per_area', axis=1, inplace=True)\n",
    "\n",
    "    temp = data.groupby('plate')['area'].agg({'plate_area_mean': 'mean', 'plate_area_std': 'std'})\n",
    "    temp.fillna(0, inplace=True)\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    \n",
    "    temp = data.groupby(['plate'])['buildYear'].agg({'plate_year_mean': 'mean', 'plate_year_std': 'std'})\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    data.plate_year_mean = data.plate_year_mean.astype('int')\n",
    "    data['comm_plate_year_diff'] = data.buildYear - data.plate_year_mean\n",
    "    data.drop('plate_year_mean', axis=1, inplace=True)\n",
    "\n",
    "    temp = data.groupby('plate')['transportNum'].agg('sum').reset_index(name='plate_transportNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['transportNum'].agg('sum').reset_index(name='com_transportNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data['transportNum_ratio'] = list(map(lambda x, y: round(x / y, 3) if y != 0 else -1,\n",
    "                                           data['com_transportNum'], data['plate_transportNum']))\n",
    "    data = data.drop(['com_transportNum', 'plate_transportNum'], axis=1)\n",
    "\n",
    "#     temp = data.groupby('plate')['all_SchoolNum'].agg('sum').reset_index(name='plate_all_SchoolNum')\n",
    "#     data = data.merge(temp, on='plate', how='left')\n",
    "#     temp = data.groupby(['communityName', 'plate'])['all_SchoolNum'].agg('sum').reset_index(name='com_all_SchoolNum')\n",
    "#     data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "#     data = data.drop(['com_all_SchoolNum', 'plate_all_SchoolNum'], axis=1)  # 没有融合\n",
    "\n",
    "    temp = data.groupby(['communityName', 'plate'])['all_mall'].agg('sum').reset_index(name='com_all_mall')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "\n",
    "    temp = data.groupby('plate')['otherNum'].agg('sum').reset_index(name='plate_otherNum')\n",
    "    data = data.merge(temp, on='plate', how='left')\n",
    "    temp = data.groupby(['communityName', 'plate'])['otherNum'].agg('sum').reset_index(name='com_otherNum')\n",
    "    data = data.merge(temp, on=['communityName', 'plate'], how='left')\n",
    "    data['other_ratio'] = list(map(lambda x, y: round(x / y, 3) if y != 0 else -1,\n",
    "                                   data['com_otherNum'], data['plate_otherNum']))\n",
    "    data = data.drop(['com_otherNum', 'plate_otherNum'], axis=1)\n",
    "\n",
    "    temp = data.groupby(['month', 'communityName']).size().reset_index(name='communityName_saleNum')\n",
    "    data = data.merge(temp, on=['month', 'communityName'], how='left')\n",
    "    temp = data.groupby(['month', 'plate']).size().reset_index(name='plate_saleNum')\n",
    "    data = data.merge(temp, on=['month', 'plate'], how='left')\n",
    "\n",
    "    data['sale_ratio'] = round((data.communityName_saleNum + 1) / (data.plate_saleNum + 1), 3)\n",
    "    data['sale_newworker_differ'] = 3 * data.plate_saleNum - data.newWorkers\n",
    "    data.drop(['communityName_saleNum', 'plate_saleNum'], axis=1, inplace=True)\n",
    "\n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    return new_train, new_test\n",
    "\n",
    "data_train, data_test = groupby(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#聚类\n",
    "def cluster(train,test):\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "\n",
    "    train['data_type'] = 0\n",
    "    test['data_type'] = 1\n",
    "    data = pd.concat([train, test], axis=0, join='outer')\n",
    "    col = ['totalFloor',\n",
    "           'houseDecoration', 'communityName', 'region', 'plate', 'buildYear',\n",
    "\n",
    "           'tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney',\n",
    "           'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum',\n",
    "\n",
    "           'landTotalPrice', 'landMeanPrice', 'totalWorkers',\n",
    "           'newWorkers', 'residentPopulation', 'lookNum',\n",
    "           'transportNum',\n",
    "           'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum']\n",
    "\n",
    "    # EM\n",
    "    gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=0)\n",
    "    data['cluster']= pd.DataFrame(gmm.fit_predict(data[col]))\n",
    "\n",
    "\n",
    "    col1 = ['totalFloor','houseDecoration', 'communityName', 'region', 'plate', 'buildYear']\n",
    "    col2 = ['tradeMeanPrice', 'tradeSecNum', 'totalNewTradeMoney',\n",
    "            'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum',\n",
    "            'landTotalPrice', 'landMeanPrice', 'totalWorkers',\n",
    "            'newWorkers', 'residentPopulation', 'lookNum',\n",
    "            'transportNum',\n",
    "            'all_SchoolNum', 'all_hospitalNum', 'all_mall', 'otherNum']\n",
    "    for feature1 in col1:\n",
    "        for feature2 in col2:\n",
    "        \n",
    "            temp = data.groupby(['cluster',feature1])[feature2].agg('mean').reset_index(name=feature2+'_'+feature1+'_cluster_mean')\n",
    "            temp.fillna(0, inplace=True)\n",
    "       \n",
    "            data = data.merge(temp, on=['cluster', feature1], how='left')\n",
    "    \n",
    "   \n",
    "    new_train = data[data['data_type'] == 0]\n",
    "    new_test = data[data['data_type'] == 1]\n",
    "    new_train.drop('data_type', axis=1, inplace=True)\n",
    "    new_test.drop(['data_type'], axis=1, inplace=True)\n",
    "    \n",
    "    return new_train, new_test\n",
    "\n",
    "data_train, data_test = cluster(data_train, data_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过大量级值取log平滑（针对线性模型有效）\n",
    "big_num_cols = ['totalTradeMoney','totalTradeArea','tradeMeanPrice','totalNewTradeMoney', 'totalNewTradeArea',\n",
    "                'tradeNewMeanPrice','remainNewNum', 'supplyNewNum', 'supplyLandArea',\n",
    "                'tradeLandArea','landTotalPrice','landMeanPrice','totalWorkers','newWorkers',\n",
    "                'residentPopulation','pv','uv']\n",
    "\n",
    "for col in big_num_cols:\n",
    "        data_train[col] = data_train[col].map(lambda x: np.log1p(x))\n",
    "        data_test[col] = data_test[col].map(lambda x: np.log1p(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集结果： 0.7299971022440981\n",
      "测试集结果： 0.813833276187229\n"
     ]
    }
   ],
   "source": [
    "#对比特征工程前后线性模型结果情况\n",
    "data_test = data_test.fillna(0)\n",
    "data_train = data_train.fillna(0)\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso=Lasso(alpha=0.1,fit_intercept = True)\n",
    "lasso.fit(data_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(data_train)\n",
    "y_pred_test=lasso.predict(data_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40134, 177)\n",
      "(40134, 150)\n",
      "[  0   1   3   4   5   6   7   8   9  10  12  13  14  15  16  17  18  19\n",
      "  20  21  22  24  27  28  29  30  33  34  35  37  38  39  40  41  43  44\n",
      "  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62\n",
      "  64  66  68  69  70  71  72  73  74  75  76  77  78  79  80  81  83  84\n",
      "  85  86  87  88  89  90  92  93  94  95  96  97  98  99 100 101 102 103\n",
      " 104 105 106 108 109 110 111 114 116 117 119 120 121 122 123 124 125 126\n",
      " 127 128 129 132 133 134 135 136 137 138 139 140 141 142 144 145 146 147\n",
      " 150 151 152 153 155 156 157 158 159 160 161 162 163 164 165 168 169 170\n",
      " 171 172 173 174 175 176]\n",
      "Index(['area', 'rentType', 'totalFloor', 'houseToward', 'houseDecoration',\n",
      "       'communityName', 'region', 'plate', 'buildYear', 'saleSecHouseNum',\n",
      "       ...\n",
      "       'remainNewNum_buildYear_cluster_mean',\n",
      "       'totalWorkers_buildYear_cluster_mean',\n",
      "       'newWorkers_buildYear_cluster_mean',\n",
      "       'residentPopulation_buildYear_cluster_mean',\n",
      "       'lookNum_buildYear_cluster_mean', 'transportNum_buildYear_cluster_mean',\n",
      "       'all_SchoolNum_buildYear_cluster_mean',\n",
      "       'all_hospitalNum_buildYear_cluster_mean',\n",
      "       'all_mall_buildYear_cluster_mean', 'otherNum_buildYear_cluster_mean'],\n",
      "      dtype='object', length=150)\n",
      "(2469, 150)\n",
      "训练集结果： 0.7166177380996134\n",
      "测试集结果： 0.7952516546097608\n"
     ]
    }
   ],
   "source": [
    "#相关系数法特征选择\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "print(data_train.shape)\n",
    "\n",
    "sk = SelectKBest(k=150)\n",
    "new_train = sk.fit_transform(data_train,target_train)\n",
    "print(new_train.shape)\n",
    "\n",
    "# 获取对应列索引\n",
    "select_columns=sk.get_support(indices = True)\n",
    "print(select_columns)\n",
    "\n",
    "# 获取对应列名\n",
    "print(data_train.columns[select_columns])\n",
    "select_columns_name=data_test.columns[select_columns]\n",
    "new_test=data_test[select_columns_name]\n",
    "print(new_test.shape)\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['area', 'rentType', 'houseFloor', 'totalFloor', 'houseToward', 'houseDecoration', 'region', 'plate', 'buildYear', 'saleSecHouseNum', 'totalTradeMoney', 'totalTradeArea', 'tradeMeanPrice', 'totalNewTradeMoney', 'totalNewTradeArea', 'tradeNewMeanPrice', 'tradeNewNum', 'remainNewNum', 'supplyNewNum', 'supplyLandNum', 'supplyLandArea', 'tradeLandNum', 'tradeLandArea', 'landTotalPrice', 'landMeanPrice', 'totalWorkers', 'newWorkers', 'residentPopulation', 'pv', 'uv', 'lookNum', 'room', 'hall', 'bath', 'month', 'pv/uv', '房间总数', 'transportNum', 'all_SchoolNum', 'all_mall', 'all_hospitalNum', 'otherNum', 'count_communityName_totalFloor', 'com_area_mean', 'plate_area_mean', 'plate_area_std', 'plate_year_std', 'comm_plate_year_diff', 'transportNum_ratio', 'other_ratio', 'sale_ratio', 'cluster', 'lookNum_totalFloor_cluster_mean', 'transportNum_totalFloor_cluster_mean', 'all_SchoolNum_totalFloor_cluster_mean', 'all_hospitalNum_totalFloor_cluster_mean', 'all_mall_totalFloor_cluster_mean', 'otherNum_totalFloor_cluster_mean', 'tradeSecNum_houseDecoration_cluster_mean', 'totalNewTradeArea_houseDecoration_cluster_mean', 'tradeNewNum_houseDecoration_cluster_mean', 'remainNewNum_houseDecoration_cluster_mean', 'lookNum_houseDecoration_cluster_mean', 'transportNum_houseDecoration_cluster_mean', 'all_SchoolNum_houseDecoration_cluster_mean', 'all_hospitalNum_houseDecoration_cluster_mean', 'all_mall_houseDecoration_cluster_mean', 'otherNum_houseDecoration_cluster_mean', 'tradeSecNum_communityName_cluster_mean', 'lookNum_communityName_cluster_mean', 'transportNum_communityName_cluster_mean', 'all_SchoolNum_communityName_cluster_mean', 'all_hospitalNum_communityName_cluster_mean', 'all_mall_communityName_cluster_mean', 'otherNum_communityName_cluster_mean', 'tradeSecNum_region_cluster_mean', 'tradeNewNum_region_cluster_mean', 'remainNewNum_region_cluster_mean', 'lookNum_region_cluster_mean', 'transportNum_region_cluster_mean', 'all_SchoolNum_region_cluster_mean', 'all_hospitalNum_region_cluster_mean', 'all_mall_region_cluster_mean', 'otherNum_region_cluster_mean', 'tradeSecNum_plate_cluster_mean', 'tradeNewNum_plate_cluster_mean', 'lookNum_plate_cluster_mean', 'transportNum_plate_cluster_mean', 'all_SchoolNum_plate_cluster_mean', 'all_hospitalNum_plate_cluster_mean', 'all_mall_plate_cluster_mean', 'otherNum_plate_cluster_mean', 'tradeSecNum_buildYear_cluster_mean', 'tradeNewNum_buildYear_cluster_mean', 'lookNum_buildYear_cluster_mean', 'transportNum_buildYear_cluster_mean', 'all_SchoolNum_buildYear_cluster_mean', 'all_hospitalNum_buildYear_cluster_mean', 'all_mall_buildYear_cluster_mean', 'otherNum_buildYear_cluster_mean']\n",
      "训练集结果： 0.6434826201386998\n",
      "测试集结果： 0.7326285058894892\n"
     ]
    }
   ],
   "source": [
    "# Wrapper\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(lr, n_features_to_select=100)\n",
    "rfe.fit(data_train,target_train)\n",
    "\n",
    "RFE(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
    "                               normalize=False),\n",
    "    n_features_to_select=40, step=1, verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "select_columns = [f for f, s in zip(data_train.columns, rfe.support_) if s]\n",
    "print(select_columns)\n",
    "new_train = data_train[select_columns]\n",
    "new_test = data_test[select_columns]\n",
    "\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 66  30 154 139  13 121 120  43 122 176  84  81 118 136 135 153  65 140\n",
      "  63 119  23 172  16 137  17  28   9  22 173  19 164   2   4  92 128  59\n",
      "  11  74  27 124   5  10  24 129 100  97  93  47  14 110 147 102  90   6\n",
      " 104 144  87 103  70  52  77  57  38  39 167 113  69 149 127  75  98  49\n",
      "  80 169 116 152  55  67 114 150 151  56 109 125  94 166 130 161  71 107\n",
      " 148  36 112  76 143  89 168  78 170 115  48  73 163 132  79 134 145 159\n",
      " 123 105  58 108 165  96 133 141  72  91 131 162  51 126  95  18  99  68\n",
      " 160  64 111  32 106 101 142  26  50  53 117  20  25  61  54  82  33  35\n",
      "  34 146  37   3  41  88  62 171   0  60  15 156  40  86   1   8  45  83\n",
      "  12  21  46 158 174  29  44 138 175 157 155   7  85  31  42]\n",
      "[-7.64380383e+02 -7.01000123e+02 -6.18610506e+02 -4.01673108e+02\n",
      " -3.76898538e+02 -3.74611706e+02 -3.57133169e+02 -3.16328382e+02\n",
      " -3.06687287e+02 -2.89510336e+02 -2.82427273e+02 -2.69696038e+02\n",
      " -2.67222424e+02 -2.34322618e+02 -1.81762294e+02 -1.41975945e+02\n",
      " -1.36156981e+02 -1.17240572e+02 -1.13539593e+02 -1.12371680e+02\n",
      " -1.01159467e+02 -9.32615984e+01 -9.01094040e+01 -5.94009906e+01\n",
      " -5.55796208e+01 -4.84093995e+01 -3.67972614e+01 -3.04460351e+01\n",
      " -2.93778556e+01 -1.65239746e+01 -1.63842534e+01 -1.42123383e+01\n",
      " -1.32390929e+01 -1.21935865e+01 -1.08048201e+01 -8.76815065e+00\n",
      " -8.57716454e+00 -7.51595257e+00 -7.30959884e+00 -7.23572941e+00\n",
      " -6.76153798e+00 -4.37513361e+00 -1.79326194e+00 -1.62736243e+00\n",
      " -1.58071535e+00 -1.29547654e+00 -1.24772532e+00 -1.18883580e+00\n",
      " -9.46348917e-01 -8.82345725e-01 -8.65262528e-01 -7.03842031e-01\n",
      " -6.46967063e-01 -4.97845970e-01 -4.15009982e-01 -2.50053849e-01\n",
      " -1.91110833e-01 -1.72243417e-01 -6.55454957e-02 -5.48744322e-02\n",
      " -4.27002978e-02 -3.24256088e-02 -2.75324579e-02 -2.75324573e-02\n",
      " -1.55713953e-02 -1.55547528e-02 -1.48789870e-02 -1.42986416e-02\n",
      " -1.13378053e-02 -1.12216317e-02 -7.79394226e-03 -6.57739340e-03\n",
      " -4.86605861e-03 -4.70023217e-03 -3.62854363e-03 -3.57858919e-03\n",
      " -3.14584373e-03 -1.99144556e-03 -1.75682853e-03 -1.67732170e-03\n",
      " -1.01755045e-03 -7.09626150e-04 -2.96419843e-04 -1.98784345e-06\n",
      " -1.72990182e-06 -5.80712027e-07 -4.34269200e-07 -4.23826988e-07\n",
      " -4.22368747e-07 -2.53840190e-07 -1.18071840e-07  0.00000000e+00\n",
      "  2.31618765e-07  4.64969187e-07  1.30148254e-06  2.37857362e-05\n",
      "  1.19585198e-04  1.14821055e-03  1.30222975e-03  1.70897526e-03\n",
      "  1.79617090e-03  3.49206140e-03  3.53179223e-03  4.96211918e-03\n",
      "  5.41536462e-03  7.14814277e-03  1.22698406e-02  1.48966514e-02\n",
      "  1.80753535e-02  2.06865622e-02  2.14452955e-02  2.24489007e-02\n",
      "  3.88533758e-02  4.97124486e-02  6.51969638e-02  7.36912080e-02\n",
      "  7.61458801e-02  9.72449310e-02  1.52527893e-01  1.88784306e-01\n",
      "  1.97403153e-01  2.18670046e-01  2.83602169e-01  2.84316118e-01\n",
      "  3.41083371e-01  3.48948107e-01  5.60821284e-01  6.50958164e-01\n",
      "  8.13710706e-01  1.01618074e+00  1.26655179e+00  1.99447686e+00\n",
      "  2.99420827e+00  3.59562759e+00  4.17726979e+00  4.46838060e+00\n",
      "  4.59537006e+00  4.94607663e+00  4.98676532e+00  5.47533069e+00\n",
      "  5.69175246e+00  9.39453274e+00  1.01966686e+01  1.01966686e+01\n",
      "  1.01966686e+01  1.61151756e+01  2.55076330e+01  3.03092753e+01\n",
      "  3.05900058e+01  3.07133058e+01  4.13767122e+01  4.17565519e+01\n",
      "  4.34447636e+01  5.49677638e+01  6.15685218e+01  6.41715094e+01\n",
      "  6.84072647e+01  8.82596982e+01  9.32915423e+01  9.79028094e+01\n",
      "  9.95020660e+01  1.04294611e+02  1.41485278e+02  1.55157092e+02\n",
      "  1.78949134e+02  2.10769637e+02  3.40782121e+02  3.49142281e+02\n",
      "  3.65250505e+02  4.17168740e+02  4.19383041e+02  4.55468460e+02\n",
      "  5.07617341e+02  5.49974310e+02  6.88949240e+02  6.99039871e+02\n",
      "  1.02566373e+03]\n",
      "训练集结果： 0.7298387519830931\n",
      "测试集结果： 0.813989128592729\n"
     ]
    }
   ],
   "source": [
    "# Embedded\n",
    "# 基于惩罚项的特征选择法\n",
    "# Lasso(l1)和Ridge(l2)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=5)\n",
    "ridge.fit(data_train,target_train)\n",
    "\n",
    "Ridge(alpha=5, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
    "      random_state=None, solver='auto', tol=0.001)\n",
    "\n",
    "# 特征系数排序\n",
    "coefSort = ridge.coef_.argsort()\n",
    "print(coefSort)\n",
    "\n",
    "\n",
    "# 特征系数\n",
    "featureCoefSore=ridge.coef_[coefSort]\n",
    "print(featureCoefSore)\n",
    "\n",
    "\n",
    "select_columns = [f for f, s in zip(data_train.columns, featureCoefSore) if abs(s)> 0.0000005 ] \n",
    "# 选择绝对值大于0.0000005的特征\n",
    "# print(select_columns)\n",
    "\n",
    "new_train = data_train[select_columns]\n",
    "new_test = data_test[select_columns]\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.447, 'area'), (0.1362, 'tradeMeanPrice_plate_cluster_mean'), (0.0797, 'tradeMeanPrice_communityName_cluster_mean'), (0.03, 'plate_area_mean'), (0.0255, 'com_area_mean'), (0.0203, 'plate_year_std'), (0.0193, 'plate_area_std'), (0.0155, 'tradeNewMeanPrice_plate_cluster_mean'), (0.0094, 'totalFloor'), (0.0085, 'comm_plate_year_diff'), (0.0076, 'buildYear'), (0.0073, 'tradeNewMeanPrice_communityName_cluster_mean'), (0.007, 'plate_price_mean'), (0.007, 'comm_price_mean'), (0.0065, 'transportNum'), (0.0051, 'communityName'), (0.0045, 'sale_ratio'), (0.0041, 'tradeSecNum_communityName_cluster_mean'), (0.0037, 'com_area_std'), (0.0037, 'com_all_mall'), (0.0036, 'remainNewNum_communityName_cluster_mean'), (0.0034, 'transportNum_ratio'), (0.0033, 'transportNum_plate_cluster_mean'), (0.0033, 'count_communityName'), (0.0031, 'all_SchoolNum_communityName_cluster_mean'), (0.003, 'transportNum_communityName_cluster_mean'), (0.003, 'all_hospitalNum_communityName_cluster_mean'), (0.0029, 'tradeMeanPrice'), (0.0029, 'residentPopulation'), (0.0029, 'remainNewNum_plate_cluster_mean'), (0.0029, 'other_ratio'), (0.0029, 'day'), (0.0027, 'tradeNewMeanPrice'), (0.0026, 'count_communityName_totalFloor'), (0.0025, 'year'), (0.0024, 'tradeSecNum_region_cluster_mean'), (0.0023, 'residentPopulation_plate_cluster_mean'), (0.0022, 'count_totalFloor'), (0.0021, 'comm_price_std'), (0.0021, 'all_mall_communityName_cluster_mean'), (0.0019, 'room'), (0.0019, 'plate_price_std'), (0.0019, 'houseToward'), (0.0018, 'tradeSecNum_totalFloor_cluster_mean'), (0.0018, 'count_buildYear'), (0.0018, 'all_SchoolNum_totalFloor_cluster_mean'), (0.0017, 'tradeSecNum_buildYear_cluster_mean'), (0.0017, 'tradeNewMeanPrice_buildYear_cluster_mean'), (0.0017, 'otherNum_communityName_cluster_mean'), (0.0017, 'all_mall_buildYear_cluster_mean'), (0.0016, 'tradeSecNum_plate_cluster_mean'), (0.0016, 'totalWorkers_totalFloor_cluster_mean'), (0.0016, 'totalTradeArea'), (0.0016, 'sale_newworker_differ'), (0.0016, 'remainNewNum'), (0.0016, 'pv/uv'), (0.0016, 'houseFloor'), (0.0016, 'all_SchoolNum_buildYear_cluster_mean'), (0.0015, '房间总数'), (0.0015, 'totalWorkers_buildYear_cluster_mean'), (0.0015, 'totalWorkers'), (0.0015, 'totalTradeMoney'), (0.0015, 'hall'), (0.0014, 'tradeMeanPrice_buildYear_cluster_mean'), (0.0014, 'totalWorkers_plate_cluster_mean'), (0.0014, 'residentPopulation_communityName_cluster_mean'), (0.0014, 'bath'), (0.0013, 'uv'), (0.0013, 'tradeSecNum'), (0.0013, 'count_communityName_totalTradeMoney'), (0.0012, 'tradeNewMeanPrice_totalFloor_cluster_mean'), (0.0012, 'pv'), (0.0012, 'otherNum_plate_cluster_mean'), (0.0011, 'tradeNewNum_communityName_cluster_mean'), (0.0011, 'tradeMeanPrice_totalFloor_cluster_mean'), (0.0011, 'tradeMeanPrice_region_cluster_mean'), (0.0011, 'totalNewTradeMoney_totalFloor_cluster_mean'), (0.0011, 'totalNewTradeMoney_communityName_cluster_mean'), (0.0011, 'count_communityName_newWorkers'), (0.0011, 'all_hospitalNum_region_cluster_mean'), (0.001, 'transportNum_buildYear_cluster_mean'), (0.001, 'totalNewTradeMoney'), (0.001, 'totalNewTradeArea_region_cluster_mean'), (0.001, 'landTotalPrice_buildYear_cluster_mean'), (0.001, 'landMeanPrice_buildYear_cluster_mean'), (0.0009, 'totalNewTradeArea_communityName_cluster_mean'), (0.0009, 'residentPopulation_totalFloor_cluster_mean'), (0.0009, 'residentPopulation_buildYear_cluster_mean'), (0.0009, 'remainNewNum_buildYear_cluster_mean'), (0.0009, 'landTotalPrice_totalFloor_cluster_mean'), (0.0009, 'all_mall_totalFloor_cluster_mean'), (0.0009, 'all_SchoolNum_plate_cluster_mean'), (0.0008, 'transportNum_totalFloor_cluster_mean'), (0.0008, 'tradeNewNum'), (0.0008, 'totalWorkers_communityName_cluster_mean'), (0.0008, 'totalNewTradeMoney_buildYear_cluster_mean'), (0.0008, 'saleSecHouseNum'), (0.0008, 'otherNum_buildYear_cluster_mean'), (0.0008, 'month'), (0.0008, 'all_hospitalNum_buildYear_cluster_mean'), (0.0007, 'totalNewTradeArea_buildYear_cluster_mean'), (0.0007, 'totalNewTradeArea'), (0.0007, 'otherNum_totalFloor_cluster_mean'), (0.0007, 'landMeanPrice_totalFloor_cluster_mean'), (0.0007, 'all_mall_plate_cluster_mean'), (0.0007, 'all_hospitalNum_totalFloor_cluster_mean'), (0.0007, 'all_SchoolNum_region_cluster_mean'), (0.0006, 'all_hospitalNum_plate_cluster_mean'), (0.0005, 'tradeNewNum_totalFloor_cluster_mean'), (0.0005, 'totalWorkers_houseDecoration_cluster_mean'), (0.0005, 'totalNewTradeArea_totalFloor_cluster_mean'), (0.0005, 'remainNewNum_totalFloor_cluster_mean'), (0.0005, 'newWorkers_communityName_cluster_mean'), (0.0004, 'tradeNewNum_buildYear_cluster_mean'), (0.0004, 'plate'), (0.0004, 'otherNum_region_cluster_mean'), (0.0004, 'lookNum'), (0.0004, 'all_mall_region_cluster_mean'), (0.0004, 'all_hospitalNum'), (0.0003, 'tradeSecNum_houseDecoration_cluster_mean'), (0.0003, 'tradeNewNum_plate_cluster_mean'), (0.0003, 'tradeNewMeanPrice_region_cluster_mean'), (0.0003, 'totalNewTradeMoney_houseDecoration_cluster_mean'), (0.0003, 'supplyNewNum'), (0.0003, 'remainNewNum_region_cluster_mean'), (0.0003, 'otherNum'), (0.0003, 'lookNum_communityName_cluster_mean'), (0.0003, 'lookNum_buildYear_cluster_mean'), (0.0003, 'landTotalPrice_communityName_cluster_mean'), (0.0003, 'houseDecoration'), (0.0003, 'all_SchoolNum_houseDecoration_cluster_mean'), (0.0002, 'transportNum_region_cluster_mean'), (0.0002, 'tradeNewMeanPrice_houseDecoration_cluster_mean'), (0.0002, 'tradeMeanPrice_houseDecoration_cluster_mean'), (0.0002, 'totalWorkers_region_cluster_mean'), (0.0002, 'totalNewTradeMoney_plate_cluster_mean'), (0.0002, 'totalNewTradeArea_plate_cluster_mean'), (0.0002, 'residentPopulation_region_cluster_mean'), (0.0002, 'residentPopulation_houseDecoration_cluster_mean'), (0.0002, 'rentType'), (0.0002, 'remainNewNum_houseDecoration_cluster_mean'), (0.0002, 'newWorkers_totalFloor_cluster_mean'), (0.0002, 'newWorkers_buildYear_cluster_mean'), (0.0002, 'landTotalPrice_houseDecoration_cluster_mean'), (0.0002, 'landMeanPrice_houseDecoration_cluster_mean'), (0.0002, 'landMeanPrice_communityName_cluster_mean'), (0.0002, 'all_mall_houseDecoration_cluster_mean'), (0.0002, 'all_SchoolNum'), (0.0001, 'transportNum_houseDecoration_cluster_mean'), (0.0001, 'tradeNewNum_houseDecoration_cluster_mean'), (0.0001, 'totalNewTradeMoney_region_cluster_mean'), (0.0001, 'totalNewTradeArea_houseDecoration_cluster_mean'), (0.0001, 'supplyLandArea'), (0.0001, 'otherNum_houseDecoration_cluster_mean'), (0.0001, 'newWorkers'), (0.0001, 'lookNum_totalFloor_cluster_mean'), (0.0001, 'lookNum_plate_cluster_mean'), (0.0001, 'landTotalPrice_region_cluster_mean'), (0.0001, 'landTotalPrice_plate_cluster_mean'), (0.0001, 'landMeanPrice_region_cluster_mean'), (0.0001, 'landMeanPrice'), (0.0001, 'all_mall'), (0.0001, 'all_hospitalNum_houseDecoration_cluster_mean'), (0.0, 'tradeNewNum_region_cluster_mean'), (0.0, 'tradeLandNum'), (0.0, 'tradeLandArea'), (0.0, 'supplyLandNum'), (0.0, 'region'), (0.0, 'newWorkers_region_cluster_mean'), (0.0, 'newWorkers_plate_cluster_mean'), (0.0, 'newWorkers_houseDecoration_cluster_mean'), (0.0, 'lookNum_region_cluster_mean'), (0.0, 'lookNum_houseDecoration_cluster_mean'), (0.0, 'landTotalPrice'), (0.0, 'landMeanPrice_plate_cluster_mean'), (0.0, 'cluster'), (0.0, 'bath_room')]\n",
      "训练集结果： 0.7263652650927195\n",
      "测试集结果： 0.8079217716585843\n"
     ]
    }
   ],
   "source": [
    "# Embedded\n",
    "# 基于树模型的特征选择法\n",
    "# 随机森林 平均不纯度减少（mean decrease impurity\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "# 训练随机森林模型，并通过feature_importances_属性获取每个特征的重要性分数。rf = RandomForestRegressor()\n",
    "rf.fit(data_train,target_train)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), data_train.columns),\n",
    "             reverse=True))\n",
    "\n",
    "select_columns = [f for f, s in zip(data_train.columns, rf.feature_importances_) if abs(s)> 0.00005 ] \n",
    "# 选择绝对值大于0.00005的特征\n",
    "\n",
    "new_train = data_train[select_columns]\n",
    "new_test = data_test[select_columns]\n",
    "\n",
    "# Lasso回归\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso=Lasso(alpha=0.1)\n",
    "lasso.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lasso.predict(new_train)\n",
    "\n",
    "y_pred_test=lasso.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#导入warnings包，利用过滤器来实现忽略警告语句。\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GBDT\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler() \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC,LinearRegression,LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集结果： 0.73448780527957\n",
      "测试集结果： -0.1914830664273488\n"
     ]
    }
   ],
   "source": [
    "# LinearRegression回归\n",
    "lr= LinearRegression(normalize=False,fit_intercept = True)\n",
    "lr.fit(data_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lr.predict(data_train)\n",
    "y_pred_test=lr.predict(data_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.4436, 'area'), (0.1616, 'tradeMeanPrice_plate_cluster_mean'), (0.0643, 'tradeMeanPrice_communityName_cluster_mean'), (0.0236, 'com_area_mean'), (0.0232, 'plate_area_std'), (0.0226, 'plate_year_std'), (0.0224, 'plate_area_mean'), (0.0117, 'comm_plate_year_diff'), (0.0095, 'tradeNewMeanPrice_plate_cluster_mean'), (0.0086, 'comm_price_mean'), (0.0084, 'plate_price_mean'), (0.0078, 'tradeNewMeanPrice_communityName_cluster_mean'), (0.0078, 'totalFloor'), (0.0057, 'buildYear'), (0.0048, 'sale_ratio'), (0.0047, 'transportNum'), (0.0045, 'transportNum_communityName_cluster_mean'), (0.0041, 'tradeSecNum_communityName_cluster_mean'), (0.0041, 'tradeMeanPrice'), (0.0041, 'com_all_mall'), (0.004, 'remainNewNum_communityName_cluster_mean'), (0.0039, 'other_ratio'), (0.0039, 'com_area_std'), (0.0034, 'count_communityName'), (0.0034, 'communityName'), (0.0032, 'tradeNewMeanPrice'), (0.0029, 'year'), (0.0027, 'tradeMeanPrice_buildYear_cluster_mean'), (0.0027, 'day'), (0.0027, 'all_SchoolNum_communityName_cluster_mean'), (0.0026, 'tradeSecNum'), (0.0026, 'count_communityName_totalFloor'), (0.0023, 'transportNum_ratio'), (0.0023, 'transportNum_plate_cluster_mean'), (0.0021, 'remainNewNum_plate_cluster_mean'), (0.0021, 'comm_price_std'), (0.0021, 'all_mall_buildYear_cluster_mean'), (0.0021, 'all_hospitalNum_communityName_cluster_mean'), (0.002, 'totalWorkers_communityName_cluster_mean'), (0.0019, 'room'), (0.0019, 'residentPopulation_communityName_cluster_mean'), (0.0019, 'otherNum_communityName_cluster_mean'), (0.0018, 'totalWorkers_totalFloor_cluster_mean'), (0.0018, 'totalWorkers_buildYear_cluster_mean'), (0.0018, 'residentPopulation'), (0.0018, 'count_totalFloor'), (0.0017, 'tradeSecNum_totalFloor_cluster_mean'), (0.0017, 'tradeNewMeanPrice_buildYear_cluster_mean'), (0.0017, 'totalNewTradeMoney_totalFloor_cluster_mean'), (0.0017, 'sale_newworker_differ'), (0.0017, 'pv'), (0.0017, 'houseToward'), (0.0017, 'hall'), (0.0017, 'count_buildYear'), (0.0017, 'all_hospitalNum_region_cluster_mean'), (0.0016, 'tradeSecNum_region_cluster_mean'), (0.0016, 'totalWorkers'), (0.0016, 'houseFloor'), (0.0016, 'count_communityName_totalTradeMoney'), (0.0016, 'all_mall_communityName_cluster_mean'), (0.0014, '房间总数'), (0.0014, 'uv'), (0.0014, 'tradeSecNum_buildYear_cluster_mean'), (0.0014, 'totalTradeArea'), (0.0014, 'residentPopulation_plate_cluster_mean'), (0.0014, 'remainNewNum'), (0.0014, 'pv/uv'), (0.0014, 'plate_price_std'), (0.0014, 'bath'), (0.0014, 'all_SchoolNum_totalFloor_cluster_mean'), (0.0013, 'tradeNewMeanPrice_totalFloor_cluster_mean'), (0.0013, 'totalTradeMoney'), (0.0012, 'landTotalPrice_buildYear_cluster_mean'), (0.0012, 'count_communityName_newWorkers'), (0.0012, 'all_SchoolNum_buildYear_cluster_mean'), (0.0012, 'all_SchoolNum'), (0.0011, 'tradeNewNum_communityName_cluster_mean'), (0.0011, 'tradeMeanPrice_totalFloor_cluster_mean'), (0.0011, 'residentPopulation_totalFloor_cluster_mean'), (0.0011, 'landMeanPrice_buildYear_cluster_mean'), (0.001, 'totalWorkers_plate_cluster_mean'), (0.001, 'totalNewTradeMoney_communityName_cluster_mean'), (0.001, 'totalNewTradeMoney_buildYear_cluster_mean'), (0.001, 'totalNewTradeArea_communityName_cluster_mean'), (0.001, 'month'), (0.0009, 'transportNum_totalFloor_cluster_mean'), (0.0009, 'transportNum_buildYear_cluster_mean'), (0.0009, 'residentPopulation_buildYear_cluster_mean'), (0.0009, 'otherNum_plate_cluster_mean'), (0.0009, 'otherNum_buildYear_cluster_mean'), (0.0009, 'all_hospitalNum_buildYear_cluster_mean'), (0.0008, 'tradeSecNum_plate_cluster_mean'), (0.0008, 'tradeNewNum'), (0.0008, 'tradeMeanPrice_region_cluster_mean'), (0.0008, 'totalNewTradeMoney'), (0.0008, 'totalNewTradeArea'), (0.0008, 'saleSecHouseNum'), (0.0008, 'otherNum_totalFloor_cluster_mean'), (0.0008, 'landTotalPrice_totalFloor_cluster_mean'), (0.0008, 'landMeanPrice_totalFloor_cluster_mean'), (0.0008, 'all_mall_totalFloor_cluster_mean'), (0.0007, 'totalNewTradeArea_totalFloor_cluster_mean'), (0.0007, 'totalNewTradeArea_buildYear_cluster_mean'), (0.0007, 'remainNewNum_buildYear_cluster_mean'), (0.0007, 'all_mall'), (0.0006, 'totalWorkers_region_cluster_mean'), (0.0006, 'totalWorkers_houseDecoration_cluster_mean'), (0.0006, 'remainNewNum_totalFloor_cluster_mean'), (0.0006, 'all_mall_plate_cluster_mean'), (0.0006, 'all_SchoolNum_plate_cluster_mean'), (0.0005, 'tradeNewNum_totalFloor_cluster_mean'), (0.0005, 'tradeNewNum_buildYear_cluster_mean'), (0.0005, 'tradeNewMeanPrice_region_cluster_mean'), (0.0005, 'plate'), (0.0005, 'newWorkers_communityName_cluster_mean'), (0.0005, 'all_hospitalNum_totalFloor_cluster_mean'), (0.0005, 'all_SchoolNum_region_cluster_mean'), (0.0004, 'transportNum_region_cluster_mean'), (0.0004, 'supplyNewNum'), (0.0004, 'lookNum_communityName_cluster_mean'), (0.0004, 'lookNum'), (0.0004, 'landTotalPrice_communityName_cluster_mean'), (0.0004, 'houseDecoration'), (0.0003, 'tradeNewNum_plate_cluster_mean'), (0.0003, 'tradeNewMeanPrice_houseDecoration_cluster_mean'), (0.0003, 'totalNewTradeMoney_houseDecoration_cluster_mean'), (0.0003, 'remainNewNum_region_cluster_mean'), (0.0003, 'otherNum_region_cluster_mean'), (0.0003, 'otherNum'), (0.0003, 'landMeanPrice_communityName_cluster_mean'), (0.0003, 'all_mall_region_cluster_mean'), (0.0003, 'all_hospitalNum_plate_cluster_mean'), (0.0003, 'all_SchoolNum_houseDecoration_cluster_mean'), (0.0002, 'transportNum_houseDecoration_cluster_mean'), (0.0002, 'tradeSecNum_houseDecoration_cluster_mean'), (0.0002, 'tradeMeanPrice_houseDecoration_cluster_mean'), (0.0002, 'totalNewTradeMoney_region_cluster_mean'), (0.0002, 'totalNewTradeArea_plate_cluster_mean'), (0.0002, 'rentType'), (0.0002, 'remainNewNum_houseDecoration_cluster_mean'), (0.0002, 'newWorkers_totalFloor_cluster_mean'), (0.0002, 'newWorkers_plate_cluster_mean'), (0.0002, 'newWorkers_buildYear_cluster_mean'), (0.0002, 'newWorkers'), (0.0002, 'lookNum_totalFloor_cluster_mean'), (0.0002, 'landTotalPrice_region_cluster_mean'), (0.0002, 'landTotalPrice_houseDecoration_cluster_mean'), (0.0002, 'landMeanPrice_houseDecoration_cluster_mean'), (0.0002, 'all_hospitalNum'), (0.0001, 'tradeNewNum_region_cluster_mean'), (0.0001, 'tradeNewNum_houseDecoration_cluster_mean'), (0.0001, 'tradeLandArea'), (0.0001, 'totalNewTradeMoney_plate_cluster_mean'), (0.0001, 'totalNewTradeArea_region_cluster_mean'), (0.0001, 'totalNewTradeArea_houseDecoration_cluster_mean'), (0.0001, 'supplyLandNum'), (0.0001, 'supplyLandArea'), (0.0001, 'residentPopulation_region_cluster_mean'), (0.0001, 'residentPopulation_houseDecoration_cluster_mean'), (0.0001, 'region'), (0.0001, 'otherNum_houseDecoration_cluster_mean'), (0.0001, 'lookNum_region_cluster_mean'), (0.0001, 'lookNum_plate_cluster_mean'), (0.0001, 'lookNum_buildYear_cluster_mean'), (0.0001, 'landTotalPrice_plate_cluster_mean'), (0.0001, 'landMeanPrice_region_cluster_mean'), (0.0001, 'landMeanPrice_plate_cluster_mean'), (0.0001, 'landMeanPrice'), (0.0001, 'all_mall_houseDecoration_cluster_mean'), (0.0001, 'all_hospitalNum_houseDecoration_cluster_mean'), (0.0, 'tradeLandNum'), (0.0, 'newWorkers_region_cluster_mean'), (0.0, 'newWorkers_houseDecoration_cluster_mean'), (0.0, 'lookNum_houseDecoration_cluster_mean'), (0.0, 'landTotalPrice'), (0.0, 'cluster'), (0.0, 'bath_room')]\n",
      "训练集结果： 0.7341003725180811\n",
      "测试集结果： -0.1901922493335133\n"
     ]
    }
   ],
   "source": [
    "# Randomforest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "# 训练随机森林模型，并通过feature_importances_属性获取每个特征的重要性分数。rf = RandomForestRegressor()\n",
    "rf.fit(data_train,target_train)\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), data_train.columns),\n",
    "             reverse=True))\n",
    "\n",
    "select_columns = [f for f, s in zip(data_train.columns, rf.feature_importances_) if abs(s)> 0.00005 ] \n",
    "# 选择绝对值大于0.00005的特征\n",
    "\n",
    "new_train = data_train[select_columns]\n",
    "new_test = data_test[select_columns]\n",
    "\n",
    "# LinearRegression回归\n",
    "lr= LinearRegression(normalize=False,fit_intercept = True)\n",
    "lr.fit(new_train,target_train)\n",
    "#预测测试集和训练集结果\n",
    "y_pred_train=lr.predict(new_train)\n",
    "y_pred_test=lr.predict(new_test)\n",
    "\n",
    "#对比结果\n",
    "from sklearn.metrics import r2_score\n",
    "score_train=r2_score(y_pred_train,target_train)\n",
    "print(\"训练集结果：\",score_train)\n",
    "score_test=r2_score(y_pred_test, target_test)\n",
    "print(\"测试集结果：\",score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm\n",
    "from __future__ import print_function\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "import numpy\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import colorama\n",
    "import numpy as np\n",
    "\n",
    "N_HYPEROPT_PROBES = 500\n",
    "HYPEROPT_ALGO = tpe.suggest  #  tpe.suggest OR hyperopt.rand.suggest\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "colorama.init()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def get_lgb_params(space):\n",
    "    lgb_params = dict()\n",
    "    lgb_params['boosting_type'] = space['boosting_type'] if 'boosting_type' in space else 'gbdt'\n",
    "    lgb_params['objective'] = 'regression'\n",
    "    lgb_params['metric'] = 'rmse'\n",
    "    lgb_params['learning_rate'] = space['learning_rate']\n",
    "    lgb_params['num_leaves'] = int(space['num_leaves'])\n",
    "    lgb_params['min_data_in_leaf'] = int(space['min_data_in_leaf'])\n",
    "    lgb_params['min_sum_hessian_in_leaf'] = space['min_sum_hessian_in_leaf']\n",
    "    lgb_params['max_depth'] = -1\n",
    "    lgb_params['lambda_l1'] = space['lambda_l1'] if 'lambda_l1' in space else 0.0\n",
    "    lgb_params['lambda_l2'] = space['lambda_l2'] if 'lambda_l2' in space else 0.0\n",
    "    lgb_params['max_bin'] = int(space['max_bin']) if 'max_bin' in space else 256\n",
    "    lgb_params['feature_fraction'] = space['feature_fraction']\n",
    "    lgb_params['bagging_fraction'] = space['bagging_fraction']\n",
    "    lgb_params['bagging_freq'] = int(space['bagging_freq']) if 'bagging_freq' in space else 1\n",
    "    lgb_params['nthread'] = 4\n",
    "    return lgb_params\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "obj_call_count = 0\n",
    "cur_best_score = 0 # 0 or np.inf\n",
    "log_writer = open( './lgb-hyperopt-log.txt', 'w' )\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "    global obj_call_count, cur_best_score\n",
    "\n",
    "    obj_call_count += 1\n",
    "\n",
    "    print('\\nLightGBM objective call #{} cur_best_score={:7.5f}'.format(obj_call_count,cur_best_score) )\n",
    "\n",
    "    lgb_params = get_lgb_params(space)\n",
    "\n",
    "    sorted_params = sorted(space.items(), key=lambda z: z[0])\n",
    "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
    "    print('Params: {}'.format(params_str) )\n",
    "    \n",
    "    kf = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "    out_of_fold = np.zeros(len(X_train))\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "        D_train = lgb.Dataset(X_train.iloc[train_idx], label=Y_train[train_idx])\n",
    "        D_val = lgb.Dataset(X_train.iloc[val_idx], label=Y_train[val_idx])\n",
    "        # Train\n",
    "        num_round = 10000\n",
    "        clf = lgb.train(lgb_params,\n",
    "                           D_train,\n",
    "                           num_boost_round=num_round,\n",
    "                           # metrics='mlogloss',\n",
    "                           valid_sets=D_val,\n",
    "                           # valid_names='val',\n",
    "                           # fobj=None,\n",
    "                           # feval=None,\n",
    "                           # init_model=None,\n",
    "                           # feature_name='auto',\n",
    "                           # categorical_feature='auto',\n",
    "                           early_stopping_rounds=200,\n",
    "                           # evals_result=None,\n",
    "                           verbose_eval=False,\n",
    "                           # learning_rates=None,\n",
    "                           # keep_training_booster=False,\n",
    "                           # callbacks=None\n",
    "                           )\n",
    "        # predict\n",
    "        nb_trees = clf.best_iteration\n",
    "        val_loss = clf.best_score['valid_0']\n",
    "        print('nb_trees={} val_loss={}'.format(nb_trees, val_loss))\n",
    "        out_of_fold[val_idx] = clf.predict(X_train.iloc[val_idx], num_iteration=nb_trees)\n",
    "        score = r2_score(out_of_fold, Y_train)\n",
    "\n",
    "    print('val_r2_score={}'.format(score))\n",
    "\n",
    "    log_writer.write('score={} Params:{} nb_trees={}\\n'.format(score, params_str, nb_trees ))\n",
    "    log_writer.flush()\n",
    "\n",
    "    if score>cur_best_score:\n",
    "        cur_best_score = score\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST SCORE={}'.format(cur_best_score) + colorama.Fore.RESET)\n",
    "    return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "\n",
    "space ={\n",
    "        'num_leaves': hp.quniform ('num_leaves', 10, 100, 1),\n",
    "        'min_data_in_leaf':  hp.quniform ('min_data_in_leaf', 10, 100, 1),\n",
    "        'feature_fraction': hp.uniform('feature_fraction', 0.75, 1.0),\n",
    "        'bagging_fraction': hp.uniform('bagging_fraction', 0.75, 1.0),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0, 0.01),\n",
    "#         'learning_rate': hp.loguniform('learning_rate', -5.0, -2.3),\n",
    "        'min_sum_hessian_in_leaf': hp.loguniform('min_sum_hessian_in_leaf', 0, 2.3),\n",
    "        'max_bin': hp.quniform ('max_bin', 88, 200, 1),\n",
    "        'bagging_freq': hp.quniform ('bagging_freq', 1, 15, 1),\n",
    "        'lambda_l1': hp.uniform('lambda_l1', 0, 10 ),\n",
    "        'lambda_l2': hp.uniform('lambda_l2', 0, 10 ),\n",
    "       }\n",
    "\n",
    "trials = Trials()\n",
    "best = hyperopt.fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_HYPEROPT_PROBES,\n",
    "                     trials=trials,\n",
    "                     verbose=1)\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best )\n",
    "print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
